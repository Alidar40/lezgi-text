{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc690d7-2ae2-470e-9127-b0ffad59dd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install beautifulsoup4 numpy sacremoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "11724ed9-04e6-4b8c-9e70-85d0f2516fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from urllib.request import urlopen\n",
    "from pathlib import Path\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from sacremoses import MosesPunctNormalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d595efd-1b91-4c4a-bedb-847d887501d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWNLOAD_DIR = Path(\"../data/raw/bible\")\n",
    "DOWNLOAD_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "PROCESSED_DIR = Path(\"../data/processed/\")\n",
    "PROCESSED_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# no / in the end\n",
    "SITE_URL = \"https://www.bible.com\"\n",
    "\n",
    "# first / is important\n",
    "# ?parallel is important\n",
    "lang_meta = {\n",
    "    \"az\": {\n",
    "        \"id\": 2324,\n",
    "        \"start_url\": \"/bible/2324/GEN.1.AZJ08?parallel=840\",\n",
    "    },\n",
    "    \"lez\": {\n",
    "        \"id\": 2193,\n",
    "        \"start_url\": \"/bible/2193/GEN.1.%25D0%259B%25D0%2595%25D0%2597%25D0%259F%25D0%259A?parallel=2193\",\n",
    "    },\n",
    "    \"ru_oriental\": {\n",
    "        \"id\": 385,\n",
    "        \"start_url\": \"/bible/385/GEN.1.CARS?parallel=2193\",\n",
    "    },\n",
    "    \"ru_oriental_allah\": {\n",
    "        \"id\": 840,\n",
    "        \"start_url\": \"/bible/840/GEN.1.CARS-A?parallel=2193\",\n",
    "    },\n",
    "    \"en_standart_vesrion_2016\": {\n",
    "        \"id\": 59,\n",
    "        \"start_url\": \"/bible/59/GEN.1.ESV?parallel=2193\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711a19a2-34cf-49de-8a26-816cc2e1aeec",
   "metadata": {},
   "source": [
    "## Scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ef1141b-000c-4dc9-9e9c-d0d2ac78edd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_parsing(chapter_url, lang_id):\n",
    "    global site_url, lez_chapters\n",
    "\n",
    "    next_chapter_exists = True\n",
    "    while next_chapter_exists:\n",
    "        page = urlopen(SITE_URL + chapter_url)\n",
    "        html = page.read().decode(\"utf-8\")\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "    \n",
    "        chapter_id = soup.find(\"div\", {\"class\": re.compile(r\"ChapterContent_chapter.*\")}).get('data-usfm').replace('.', '_')\n",
    "        save_file_path = DOWNLOAD_DIR / f\"{chapter_id}.{lang_id}\"\n",
    "        if not save_file_path.exists():\n",
    "            html_reader = soup.find(\"div\", {\"class\": re.compile(r\"ChapterContent_reader.*\")})\n",
    "            html_chapter_elements = html_reader.find_all(\"span\", {\"class\": re.compile(r\"ChapterContent_[heading|verse].*\")})\n",
    "            \n",
    "            headers = html_reader.find_all('h1')\n",
    "            assert len(headers) == 1\n",
    "            chapter_text = headers[0].get_text()\n",
    "            \n",
    "            for html_chapter_element in html_chapter_elements:\n",
    "                element_text = html_chapter_element.get_text()\n",
    "                if element_text == '':\n",
    "                    continue\n",
    "            \n",
    "                element_class_name = html_chapter_element.get('class')[0]\n",
    "                if 'heading' in element_class_name:\n",
    "                    chapter_text += '\\nHEADING | ' + element_text\n",
    "                elif 'verse' in element_class_name:\n",
    "                    verse_id = html_chapter_element.get('data-usfm')\n",
    "                    label_element = html_chapter_element.find(\"span\", {\"class\": re.compile(r\"ChapterContent_label.*\")})\n",
    "                    if label_element and label_element.get_text() != '#':\n",
    "                        chapter_text += '\\n' + verse_id + ' |'\n",
    "            \n",
    "                    for html_content in html_chapter_element.find_all(\"span\", {\"class\": re.compile(r\"ChapterContent_content.*\")}):\n",
    "                        if (html_content.find_parent(\"span\", {\"class\": re.compile(r\"ChapterContent_add.*\")})) is not None:\n",
    "                            continue\n",
    "                        chapter_text += ' ' + html_content.get_text().strip()\n",
    "            save_file_path.write_text(chapter_text)\n",
    "        else:\n",
    "            time.sleep(3)\n",
    "\n",
    "        next_chapter_exists = False\n",
    "        for a in soup.find_all('a', href=True):\n",
    "            if a.get_text() == \"Next Chapter\":\n",
    "                chapter_url = a.get('href')\n",
    "                print(chapter_url)\n",
    "                next_chapter_exists = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf155cf4-db1b-49a9-aaa1-f44e5f55801a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for lang, meta in lang_meta.items():\n",
    "    chapter_url = start_chapter + str(lang_id)\n",
    "    print(lang_id)\n",
    "    start_parsing(meta[\"start_url\"], lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059bec50-aa69-48df-938c-1bae77250aad",
   "metadata": {},
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f00679bb-82e7-43f3-9a06-8a6b88b33b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lez_chapters = [f.stem for f in DOWNLOAD_DIR.glob(\"*.lez\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "74d9dd80-62bf-4e55-8fd1-611beed0820d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bible_by_lang = defaultdict(list)\n",
    "for chapter in sorted(lez_chapters):\n",
    "    verses_ids_by_lang = defaultdict(list)\n",
    "    for file in DOWNLOAD_DIR.glob(f\"{chapter}.*\"):\n",
    "        lang = file.suffix[1:]\n",
    "        chapter_text = file.read_text()\n",
    "        # skip shapter name\n",
    "        chapter_text = chapter_text.split('\\n')[1:]\n",
    "        for line in chapter_text:\n",
    "            if line.startswith('HEADING'):\n",
    "                continue\n",
    "            verse_id, verse_text = line.split(' |')\n",
    "            verses_ids_by_lang[lang].append(verse_id)\n",
    "\n",
    "    # add missing verses\n",
    "    max_verse_id_by_lang = defaultdict(list)\n",
    "    for lang, verses in verses_ids_by_lang.items():\n",
    "        max_verse_id_by_lang[lang] = sorted([int(v.split('.')[-1]) for v in verses])[-1]\n",
    "\n",
    "    if len(set(max_verse_id_by_lang.values())) != 1:\n",
    "        for lang, verses in verses_ids_by_lang.items():\n",
    "            if max_verse_id_by_lang[lang] < max(max_verse_id_by_lang.values()):\n",
    "                first_part = '.'.join(verses[-1].split('.')[:-1])\n",
    "                num = verses[-1].split('.')[-1]\n",
    "                verses[-1] = verses[-1] + '+' + first_part + '.' + str(int(num) + 1)\n",
    "    for lang, verses in verses_ids_by_lang.items():\n",
    "        for i in range(0, len(verses)-1):\n",
    "            cur = int(verses[i].split('.')[-1])\n",
    "            next_ = int(verses[i+1].split('.')[-1])\n",
    "            if next_ - cur > 1:\n",
    "                first_part = '.'.join(verses[i].split('.')[:-1])\n",
    "                num = verses[i].split('.')[-1]\n",
    "                verses[i] += '+' + first_part + '.' + str(int(num) + 1)\n",
    "            prev = cur\n",
    "\n",
    "    # get merged verses\n",
    "    merged_verses_ids = list()\n",
    "    good_verses = list()\n",
    "    for lang, verses in verses_ids_by_lang.items():\n",
    "        for v in verses:\n",
    "            if '+' in v:\n",
    "                merged_verses_ids.extend(v.split('+'))\n",
    "            else:\n",
    "                good_verses.append(v)\n",
    "    merged_verses_ids = sorted(list(set(merged_verses_ids)), key=lambda x: int(x.split('.')[-1]))\n",
    "\n",
    "    good_verses = set(good_verses)\n",
    "    good_verses = [v for v in good_verses if v not in merged_verses_ids]\n",
    "    \n",
    "    final_merged_verses_ids = list()\n",
    "    if len(merged_verses_ids) > 0:    \n",
    "        prev = int(merged_verses_ids[0].split('.')[-1])\n",
    "        span = merged_verses_ids[0]\n",
    "        for i in range(1, len(merged_verses_ids)):\n",
    "            if int(merged_verses_ids[i].split('.')[-1]) - prev == 1:\n",
    "                span += '+' + merged_verses_ids[i]\n",
    "            else:\n",
    "                final_merged_verses_ids.append(span)\n",
    "                span = merged_verses_ids[i]\n",
    "            prev = int(merged_verses_ids[i].split('.')[-1])\n",
    "        final_merged_verses_ids.append(span)\n",
    "\n",
    "        # print(merged_verses_ids)\n",
    "        # print(final_merged_verses_ids)\n",
    "        # print(sorted(good_verses))\n",
    "        # print()\n",
    "    \n",
    "    final_verses = sorted(good_verses + final_merged_verses_ids, key=lambda x: int(x.split('.')[-1]))\n",
    "\n",
    "    for file in DOWNLOAD_DIR.glob(f\"{chapter}.*\"):\n",
    "        lang = file.suffix[1:]\n",
    "        chapter_text = file.read_text()\n",
    "        # skip shapter name\n",
    "        chapter_text = chapter_text.split('\\n')[1:]\n",
    "        prev_verse_text = ''\n",
    "        for line in chapter_text:\n",
    "            if line.startswith('HEADING'):\n",
    "                continue\n",
    "            verse_id, verse_text = line.split(' |')\n",
    "            if verse_id in final_verses:\n",
    "                if len(prev_verse_text) > 0:\n",
    "                    bible_by_lang[lang].append(prev_verse_text)\n",
    "                    prev_verse_text = ''\n",
    "                bible_by_lang[lang].append(verse_text.strip())\n",
    "            else:\n",
    "                prev_verse_text += verse_text.strip() + ' '\n",
    "        if len(prev_verse_text) > 0:\n",
    "            bible_by_lang[lang].append(prev_verse_text)\n",
    "            prev_verse_text = ''\n",
    "\n",
    "    if len(set([len(v) for v in bible_by_lang.values()])) != 1:\n",
    "        print(chapter)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "9302419a-166d-442b-b3da-aee10f7e0e1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([13617, 13617, 13617, 13617, 13617],\n",
       " ['lez', 'ru_oriental', 'az', 'ru_oriental_allah', 'en_standart_vesrion_2016'])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(v) for v in bible_by_lang.values()], [v for v in bible_by_lang.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "8a6ce41e-b19d-4a79-b3ee-cfcda7215762",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_extra_whitespaces(text):\n",
    "    text = text.replace('*', ' ').replace(' .', '.')\n",
    "    text = text.replace(' ,', ',').replace(' !', '!').replace(' ?', '?')\n",
    "    text = re.sub(r' +', ' ', text)\n",
    "    text = '\\n'.join(l.strip() for l in text.split('\\n'))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "df427942-0f8d-4861-8f5d-584424eedf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lang, verses in bible_by_lang.items():\n",
    "    output_file = PROCESSED_DIR / f\"bible.{lang}\"\n",
    "\n",
    "    normalizer = MosesPunctNormalizer(\n",
    "        lang=lang.split('_')[0],\n",
    "        penn=True,\n",
    "        norm_quote_commas=True,\n",
    "        norm_numbers=True,\n",
    "        pre_replace_unicode_punct=False,\n",
    "        post_remove_control_chars=False,\n",
    "        perl_parity=False,\n",
    "    )\n",
    "\n",
    "    text = '\\n'.join(verses)\n",
    " \n",
    "    text = remove_extra_whitespaces(text)\n",
    "    text = normalizer.normalize(text)\n",
    "\n",
    "    output_file.write_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "cf7f9d06-b9dc-46f1-b146-1673c7d9ea7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   13616 ../data/processed/bible.az\n",
      "   13616 ../data/processed/bible.en_standart_vesrion_2016\n",
      "   13616 ../data/processed/bible.lez\n",
      "   13616 ../data/processed/bible.ru_oriental\n",
      "   13616 ../data/processed/bible.ru_oriental_allah\n",
      "   68080 total\n"
     ]
    }
   ],
   "source": [
    "!wc -l {PROCESSED_DIR}/bible.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e987565d-665f-4da5-ae3c-2bd45e8180c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
